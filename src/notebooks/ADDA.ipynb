{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc2f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from argparse import Namespace\n",
    "import tqdm\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import gzip\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f793e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLOBALS \n",
    "SOURCE_GENOME=\"mm10\"\n",
    "TF=\"CEBPA\"\n",
    "SOURCE_GENOME_FASTA='../../genomes/mm10_no_alt_analysis_set_ENCODE.fasta'\n",
    "TARGET_GENOME = \"hg38\"\n",
    "TARGET_GENOME_FASTA = \"../../genomes/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta\"\n",
    "PILOT_STUDY=False\n",
    "MODEL_NAME=\"adda\"\n",
    "PYTORCH_DEVICE=\"cuda\"\n",
    "TRAIN=True\n",
    "MODEL_STORAGE_SUFFIX=\"_pilot\" if PILOT_STUDY else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc51357",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")\n",
    "from utils import datasets,samplers,models,utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5302b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger config\n",
    "logging.basicConfig(filename=f'./log/{TF}_{MODEL_NAME}{MODEL_STORAGE_SUFFIX}.log', filemode='w', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14b44f0",
   "metadata": {},
   "source": [
    "# Define namespace arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c649da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\t../../torch_models/mm10/CEBPA/adda_debug/adda_debug.pth\n",
      "Using CUDA: True\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # Data and Path information\n",
    "    model_state_file=f'{MODEL_NAME}{MODEL_STORAGE_SUFFIX}.pth',\n",
    "    source_csv=f'../../data/{SOURCE_GENOME}/{TF}/split_data.csv.gz',\n",
    "    source_genome_fasta=SOURCE_GENOME_FASTA,\n",
    "    target_csv = f'../../data/{TARGET_GENOME}/{TF}/split_data.csv.gz',\n",
    "    target_genome_fasta = TARGET_GENOME_FASTA,\n",
    "    model_save_dir=f'../../torch_models/{SOURCE_GENOME}/{TF}/{MODEL_NAME}/',\n",
    "    results_save_dir=f'../../results/{SOURCE_GENOME}/{TF}/',\n",
    "    feat_size=(4, 500),\n",
    "    \n",
    "    # Model hyper parameters\n",
    "    conv_filters=240,\n",
    "    conv_kernelsize=20,\n",
    "    maxpool_strides=15,\n",
    "    maxpool_size=15,\n",
    "    lstm_outnodes=32,\n",
    "    linear1_nodes=1024,\n",
    "    dropout_prob=0.5,\n",
    "    \n",
    "    # Training hyper parameters\n",
    "    batch_size=512,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=5,\n",
    "    tolerance=1e-3,\n",
    "    seed=1337,\n",
    "    \n",
    "    # Runtime options\n",
    "    catch_keyboard_interrupt=True,\n",
    "    cuda=True if PYTORCH_DEVICE==\"cuda\" else False,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    "    pilot=PILOT_STUDY, # 2% of original dataset\n",
    "    train=TRAIN,\n",
    "    test_batch_size=int(2e3)\n",
    ")\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "\n",
    "    args.model_state_file = os.path.join(args.model_save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "    \n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "utils.set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "utils.handle_dirs(args.model_save_dir)\n",
    "utils.handle_dirs(args.results_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789fbe8",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a7944d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(encoder, classifier, dataset, args, \n",
    "               dataset_split=\"test\", mini=False,  \n",
    "               save=True, save_file_suffix=\"\", dataset_type=\"src\"):\n",
    "    \n",
    "    # initilize models\n",
    "    classifier = classifier.to(args.device)\n",
    "    encoder = encoder.to(args.device) \n",
    "    \n",
    "    # initializing loss\n",
    "    loss_func = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # samplers and batches\n",
    "    dataset.set_split(dataset_split)\n",
    "    \n",
    "    test_sampler = utils.get_test_sampler(dataset, mini=mini)\n",
    "    \n",
    "    batch_generator = utils.generate_batches(dataset, sampler=test_sampler, shuffle=False, \n",
    "                                       batch_size=args.test_batch_size, \n",
    "                                       device=args.device, drop_last=False)\n",
    "\n",
    "    \n",
    "    running_loss = 0.\n",
    "    running_aps = 0.\n",
    "    y_preds = []\n",
    "    y_targets = []\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "    \n",
    "    if save:\n",
    "        mode = \"wb\"\n",
    "        save_file_replace = f\"_{dataset_type}{save_file_suffix}.csv.gz\"\n",
    "        save_filename = os.path.basename(args.model_state_file).replace(\".pth\", save_file_replace)\n",
    "        save_file = os.path.join(args.results_save_dir, save_filename)\n",
    "        \n",
    "    if mini:\n",
    "        nsamples = test_sampler.num_samples\n",
    "    else:\n",
    "        nsamples = len(dataset)\n",
    "    \n",
    "    # Runnning evaluation routine\n",
    "    test_bar = tqdm.notebook.tqdm(desc=f'split={dataset_split}',\n",
    "                          total=nsamples//args.test_batch_size, \n",
    "                          position=2, \n",
    "                          leave=False)\n",
    "    \n",
    "    \n",
    "    for batch_index, batch_dict in enumerate(batch_generator):\n",
    "        # compute the output\n",
    "        y_pred = classifier(encoder(x_in=batch_dict['x_data'].float()))\n",
    "        \n",
    "        if save:\n",
    "            utils.save_test_pred(save_file, torch.sigmoid(y_pred), batch_dict['y_target'], batch_dict[\"genome_loc\"], mode=mode)\n",
    "            mode = \"ab\" \n",
    "\n",
    "        # compute the loss\n",
    "        loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "        # compute the average precision score\n",
    "        aps_t = utils.compute_aps(y_pred, batch_dict['y_target'])\n",
    "        running_aps += (aps_t - running_aps) / (batch_index + 1)\n",
    "\n",
    "        # update test bar\n",
    "        test_bar.set_postfix(loss=running_loss, \n",
    "                              aps=running_aps, \n",
    "                              batch=batch_index)\n",
    "        test_bar.update()\n",
    "    \n",
    "    return save_file if save else (running_loss, running_aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d9a0962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encoder(encoder, hybrid_model_path):\n",
    "    hybrid_model_dict = torch.load(hybrid_model_path)\n",
    "    enc_dict = {k.replace(\"featurizer.\", \"\", 1):v for k,v in hybrid_model_dict.items() if k.startswith(\"featurizer\")}\n",
    "    encoder.load_state_dict(enc_dict)\n",
    "    return encoder\n",
    "\n",
    "\n",
    "def load_classifier(classifier, hybrid_model_path):\n",
    "    hybrid_model_dict = torch.load(hybrid_model_path)\n",
    "    class_dict = {k.replace(\"classifier.\", \"\", 1):v for k,v in hybrid_model_dict.items() if k.startswith(\"classifier\")}\n",
    "    classifier.load_state_dict(class_dict)\n",
    "    return classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f42dba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_requires_grad(model, requires_grad=True):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad=requires_grad\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db98bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tgt(src_encoder, tgt_encoder, classifier, discriminator, src_dataset, tgt_dataset, args):\n",
    "\n",
    "    # samplers for source and target data\n",
    "    src_dataset.set_split(\"train\")\n",
    "    src_sampler = samplers.get_sampler(src_dataset, weighted=False, mini=True)\n",
    "    tgt_dataset.set_split(\"train\")\n",
    "    tgt_sampler = samplers.get_sampler(tgt_dataset, weighted=False, mini=True)\n",
    "        \n",
    "    # encoders, discriminator and classifier initialization\n",
    "    src_encoder = src_encoder.to(args.device)\n",
    "    tgt_encoder = tgt_encoder.to(args.device)\n",
    "    discriminator = discriminator.to(args.device)\n",
    "    classifier = classifier.to(args.device)\n",
    "    \n",
    "    encoder_filename = os.path.join(args.model_save_dir, f\"{MODEL_NAME}_tgt_enc.pth\")\n",
    "    discriminator_filename = os.path.join(args.model_save_dir, f\"{MODEL_NAME}_dscm.pth\")\n",
    "    \n",
    "    # Initializing loss, optimizer and scheduler\n",
    "    loss_func = nn.BCEWithLogitsLoss()\n",
    "    optimizer_tgt = optim.Adam(tgt_encoder.parameters(), \n",
    "                               lr=0.0001,\n",
    "                               betas=(0.5, 0.9))\n",
    "    optimizer_dscm = optim.Adam(discriminator.parameters(), \n",
    "                               lr=0.0001,\n",
    "                               betas=(0.5, 0.9))\n",
    "    \n",
    "    ### Training Routine ###\n",
    "    num_epochs = args.num_epochs\n",
    "    epoch_bar = tqdm.notebook.tqdm(desc='training routine', \n",
    "                          total=num_epochs,\n",
    "                          position=0)\n",
    "    batch_size=args.batch_size\n",
    "    train_bar = tqdm.notebook.tqdm(desc=f'split=train',\n",
    "                              total=min(src_sampler.num_samples//batch_size, tgt_sampler.num_samples//batch_size), \n",
    "                              position=1, \n",
    "                              leave=True)\n",
    "    \n",
    "    logging.debug(f\"Source samples: {src_sampler.num_samples}, Target samples: {tgt_sampler.num_samples}\")\n",
    "    \n",
    "    init_src_encoder_dict = copy.deepcopy(src_encoder.state_dict())\n",
    "    \n",
    "    try:\n",
    "        for epoch_index in range(num_epochs):\n",
    "            \n",
    "            # verify before every epoch that the src encoder did not change... \n",
    "            for t1, t2 in zip(init_src_encoder_dict.values(), src_encoder.state_dict().values()):\n",
    "                assert torch.equal(t1, t2)\n",
    "\n",
    "            \n",
    "            src_dataset.set_split('train')\n",
    "            src_batch_generator = utils.generate_batches(src_dataset, sampler=src_sampler,\n",
    "                                               batch_size=batch_size, \n",
    "                                               device=args.device)\n",
    "            tgt_dataset.set_split('train')\n",
    "            tgt_batch_generator = utils.generate_batches(tgt_dataset, sampler=tgt_sampler,\n",
    "                                               batch_size=batch_size, \n",
    "                                               device=args.device)\n",
    "            running_loss_dscm = 0.0\n",
    "            running_loss_tgt = 0.0\n",
    "            running_domainacc = 0.0\n",
    "            tgt_encoder.train()\n",
    "            discriminator.train()\n",
    "\n",
    "            for batch_index, (src_batch_dict, tgt_batch_dict) in enumerate(zip(src_batch_generator, tgt_batch_generator)):\n",
    "                \n",
    "                ### Discriminator Training Routine ###\n",
    "                if batch_index%10==0:\n",
    "                    \n",
    "                    set_requires_grad(src_encoder, requires_grad=False)\n",
    "                    set_requires_grad(tgt_encoder, requires_grad=False)\n",
    "                    set_requires_grad(discriminator, requires_grad=True)\n",
    "                \n",
    "                    # --------------------------------------\n",
    "                        # zero the gradients\n",
    "                    optimizer_dscm.zero_grad()\n",
    "\n",
    "                    # extract source and target features\n",
    "                    feat_src = src_encoder(src_batch_dict['x_data'].float())\n",
    "                    feat_tgt = tgt_encoder(tgt_batch_dict['x_data'].float())\n",
    "                    feat_concat = torch.cat((feat_src, feat_tgt), 0).detach()\n",
    "                    assert feat_concat.requires_grad == False\n",
    "\n",
    "                    # predict\n",
    "                    pred_concat = discriminator(feat_concat)\n",
    "\n",
    "                    # prepare labels\n",
    "                    label_src = torch.ones(batch_size, dtype=torch.float, device=args.device)\n",
    "                    label_tgt = torch.zeros(batch_size, dtype=torch.float, device=args.device)\n",
    "                    label_concat = torch.cat((label_src, label_tgt), 0)\n",
    "\n",
    "                    # compute loss due to source\n",
    "                    loss_dscm = loss_func(pred_concat, label_concat)\n",
    "\n",
    "                    # use loss to produce gradients\n",
    "                    loss_dscm.backward()                \n",
    "\n",
    "                    # optimizer step\n",
    "                    optimizer_dscm.step()\n",
    "\n",
    "\n",
    "                    # compute overall loss\n",
    "                    loss_t = loss_dscm.item()\n",
    "                    running_loss_dscm += (loss_t - running_loss_dscm) / (batch_index + 1)\n",
    "\n",
    "\n",
    "                    # compute domain accuracy\n",
    "                    domain_hat = torch.sigmoid(pred_concat)>0.5\n",
    "                    domain_hat = domain_hat.long()\n",
    "                    acc_domain = torch.sum(domain_hat==label_concat)/len(label_concat)\n",
    "                    acc_domain = acc_domain.item()\n",
    "                    running_domainacc += (acc_domain - running_domainacc) / (batch_index + 1)\n",
    "                \n",
    "                \n",
    "                # -----------------------------------------               \n",
    "                ### Target Encoder Training Routine ###\n",
    "                \n",
    "                set_requires_grad(tgt_encoder, requires_grad=True)\n",
    "                set_requires_grad(discriminator, requires_grad=False)\n",
    "                \n",
    "                # Step 1. zero the gradients\n",
    "                optimizer_dscm.zero_grad()\n",
    "                optimizer_tgt.zero_grad()\n",
    "                \n",
    "                # Step 2. Extract target features\n",
    "                feat_tgt = tgt_encoder(tgt_batch_dict['x_data'].float())\n",
    "                assert feat_tgt.requires_grad == True\n",
    "                                \n",
    "                # Step 3. Predict using discriminator\n",
    "                pred_tgt = discriminator(feat_tgt)\n",
    "                                \n",
    "                # Step 4. Prepare fake labels\n",
    "                label_tgt = torch.ones(batch_size, dtype=torch.float, device=args.device)\n",
    "                \n",
    "                # Step 5. Compute loss for target encoder\n",
    "                loss_tgt = loss_func(pred_tgt, label_tgt)\n",
    "                \n",
    "                # Step 6. Use loss to produce gradients\n",
    "                loss_tgt.backward()\n",
    "                \n",
    "                # Step 7. optimize target encoder\n",
    "                optimizer_tgt.step()\n",
    "                                \n",
    "                loss_t = loss_tgt.item()\n",
    "                running_loss_tgt += (loss_t - running_loss_tgt) / (batch_index + 1)\n",
    "                                \n",
    "                # update bar\n",
    "                train_bar.set_postfix(loss_disc=running_loss_dscm,\n",
    "                                      loss_tgt=running_loss_tgt,\n",
    "                                      dacc=running_domainacc, \n",
    "                                      epoch=epoch_index)\n",
    "                train_bar.update()\n",
    "            \n",
    "            \n",
    "            train_bar.n = 0\n",
    "            \n",
    "            torch.save(tgt_encoder.state_dict(), encoder_filename)\n",
    "            torch.save(discriminator.state_dict(), discriminator_filename)\n",
    "                \n",
    "            epoch_bar.update()\n",
    "            \n",
    "                \n",
    "    except KeyboardInterrupt:       \n",
    "        logging.info(\"Exiting loop\")\n",
    "        \n",
    "    \n",
    "    return encoder_filename, discriminator_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc99677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adda(args):\n",
    "    \n",
    "    # load dataset\n",
    "    src_dataset, tgt_dataset = datasets.load_data(args)\n",
    "    \n",
    "    \n",
    "    # initialize models\n",
    "    src_encoder = models.TFCNN(channels=args.feat_size[0],\n",
    "                               conv_filters=args.conv_filters, \n",
    "                               conv_kernelsize=args.conv_kernelsize,\n",
    "                               maxpool_size=args.maxpool_size,\n",
    "                               maxpool_strides=args.maxpool_strides)\n",
    "    \n",
    "    src_classifier = models.TFLSTM(input_features=args.conv_filters, \n",
    "                            lstm_nodes=args.lstm_outnodes, \n",
    "                            fc1_nodes=args.linear1_nodes)\n",
    "    \n",
    "    tgt_encoder =models.TFCNN(channels=args.feat_size[0],\n",
    "                              conv_filters=args.conv_filters, \n",
    "                              conv_kernelsize=args.conv_kernelsize,\n",
    "                              maxpool_size=args.maxpool_size, \n",
    "                              maxpool_strides=args.maxpool_strides)\n",
    "    \n",
    "    linear_layer_in = int(np.floor((args.feat_size[1] - args.maxpool_size - 2)/args.maxpool_strides + 1)*args.conv_filters)\n",
    "    discriminator = models.TFMLP(input_features=linear_layer_in, \n",
    "                          fc1_nodes=args.linear1_nodes, \n",
    "                          dropout_prob=0.5)\n",
    "    \n",
    "    \n",
    "    # load source model from pretrained hybrid model\n",
    "    logging.debug(\"==== Loading model for source domain ====\")\n",
    "    logging.debug(\">>> Source Encoder <<<\")\n",
    "    logging.debug(f\"{src_encoder}\")\n",
    "    logging.debug(\">>> Source Classifier <<<\")\n",
    "    logging.debug(f\"{src_classifier}\")\n",
    "    \n",
    "    ## TODO: Load state dict from hybrid model\n",
    "    hybrid_model_path = f\"../../torch_models/{SOURCE_GENOME}/{TF}/hybrid/hybrid.pth\"    \n",
    "    \n",
    "    src_encoder = load_encoder(src_encoder, hybrid_model_path) \n",
    "    src_classifier = load_classifier(src_classifier,  hybrid_model_path)\n",
    "    \n",
    "    src_encoder_filename = os.path.join(args.model_save_dir, \n",
    "                                   f\"{MODEL_NAME}_src_enc.pth\")\n",
    "    classifier_filename = os.path.join(args.model_save_dir, \n",
    "                                   f\"{MODEL_NAME}_class.pth\")\n",
    "    \n",
    "    # save source encoder and classifier\n",
    "    torch.save(src_encoder.state_dict(), src_encoder_filename)\n",
    "    torch.save(src_classifier.state_dict(), classifier_filename)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # train target encoder by GAN\n",
    "    logging.debug(\"==== Training encoder for target domain ====\")\n",
    "    logging.debug(\">>> Target Encoder <<<\")\n",
    "    logging.debug(f\"{tgt_encoder}\")\n",
    "    logging.debug(\">>> Discriminator <<<\")\n",
    "    logging.debug(f\"{discriminator}\")\n",
    "    \n",
    "    # initialize target encoder from source encoder model path\n",
    "    tgt_encoder.load_state_dict(torch.load(src_encoder_filename))\n",
    "    # initialize classifier from path\n",
    "    src_classifier.load_state_dict(torch.load(classifier_filename))\n",
    "    \n",
    "    # train target encoder\n",
    "    tgt_encoder_filename, discriminator_filename = train_tgt(src_encoder, tgt_encoder, \n",
    "                                                             src_classifier, discriminator, \n",
    "                                                             src_dataset, tgt_dataset, args)\n",
    "\n",
    "    return src_encoder_filename, classifier_filename, tgt_encoder_filename, discriminator_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f70a80fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193eba6fffae47a298c71907d30c6fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training routine:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1106b3ee6241d0991b936cd7044e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/d/dzb5732/work/.dda/lib/python3.7/site-packages/torch/nn/modules/conv.py:295: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/aten/src/ATen/native/Convolution.cpp:660.)\n",
      "  self.padding, self.dilation, self.groups)\n",
      "/storage/home/d/dzb5732/work/.dda/lib/python3.7/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    src_encoder_filename, classifier_filename, tgt_encoder_filename, discriminator_filename = train_adda(args)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc030ad",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21dcd5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_encoder_filename = os.path.join(args.model_save_dir, f\"{MODEL_NAME}_src_enc.pth\")\n",
    "classifier_filename = os.path.join(args.model_save_dir, f\"{MODEL_NAME}_class.pth\")\n",
    "tgt_encoder_filename = os.path.join(args.model_save_dir, f\"{MODEL_NAME}_tgt_enc.pth\")\n",
    "\n",
    "src_encoder = models.TFCNN(channels=args.feat_size[0], conv_filters=args.conv_filters, conv_kernelsize=args.conv_kernelsize,\n",
    "                   maxpool_size=args.maxpool_size, maxpool_strides=args.maxpool_strides)\n",
    "src_classifier = models.TFLSTM(input_features=args.conv_filters, lstm_nodes=args.lstm_outnodes, fc1_nodes=args.linear1_nodes)\n",
    "tgt_encoder = models.TFCNN(channels=args.feat_size[0], conv_filters=args.conv_filters, conv_kernelsize=args.conv_kernelsize,\n",
    "                   maxpool_size=args.maxpool_size, maxpool_strides=args.maxpool_strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45b6c6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_encoder.load_state_dict(torch.load(tgt_encoder_filename))\n",
    "src_classifier.load_state_dict(torch.load(classifier_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a7842e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data, tgt_data = datasets.load_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03100e26",
   "metadata": {},
   "source": [
    "## Target encoder on source and target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa1e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_model(src_encoder, src_classifier, src_data, args, \n",
    "           save_file_suffix=\"\", dataset_type=\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(tgt_encoder, src_classifier, tgt_data, args, \n",
    "           save_file_suffix=\"\", dataset_type=\"tgt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb93b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
